# Embedded-ML-Projects
Federated Learning on Multimodal Sensor Data

Motivation:
The main reason we wanted to pick this project was because we want to learn more about machine learning. We have really only scratched the surface of it in our previous classes so this would be a great opportunity to dive deeper. The hands-on experience we will gain from this will be helpful for us in our future careers since it seems like this is the direction the industry is headed to. 

Design Goals:
The purpose of this project is to reproduce the results in the paper with the data provided. We want to design our software based off of the repository provided in the paper. The ultimate goal for this design is to get the same results as the paper with this new data set.

Deliverables:
Reproduce results in the paper with data set provided 
Understand this type of machine learning
Accuracy analysis with graphs and tables 
Evaluate system with a multimodal dataset with graphs and tables as well

system blocks: (like a logic diagram)

hw/sw requirements: no hardware requirements, Python, Laptop with CUDA-enabled GPU (optional)

project timeline:
Week 1: Understand the basics and setup
Week 2: Delve deeper into the project's specifics
Week 3: Analyze the results and datasets
Week 4: Evaluate on balanced datasets
Week 5: optimize and benchmark
Week 6: Presentation and Conclusion

References:
Multimodal Federated Learning on IOT Data 
(https://pure-research.york.ac.uk/ws/portalfiles/portal/79047763/2109.04833v2.pdf) 
Communication-Efficient learning of deep networks from decentralized data
(http://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a.pdf

team members responsibilities:
Setup: Tianheng
Software: both
Networking: Shawn
Writing: Shawn
Research: both 
algorithm design: Tianheng
